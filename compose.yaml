services:
  weaviate:
    image: semitechnologies/weaviate:latest
    container_name: weaviate
    restart: unless-stopped
    ports: ["8080:8080"]
    environment:
      QUERY_DEFAULTS_LIMIT: "30"
      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: "true"
      PERSISTENCE_DATA_PATH: "/var/lib/weaviate"
      DEFAULT_VECTORIZER_MODULE: "none"
      ENABLE_MODULES: ""
    volumes:
      - weaviate_data:/var/lib/weaviate

  ollama:
    image: ollama/ollama:latest
    container_name: ollama
    restart: unless-stopped
    ports: ["11434:11434"]     # only expose if you want LAN access
    volumes:
      - ollama_data:/root/.ollama
    environment:
      - OLLAMA_MODEL=${OLLAMA_MODEL_NAME:-llama3.1:8b-instruct-q4_K_M}
    healthcheck:
      test: ["CMD", "ollama", "list"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s

  ollama-init:
    image: ollama/ollama:latest
    container_name: ollama-init
    depends_on:
      ollama:
        condition: service_healthy
    volumes:
      - ollama_data:/root/.ollama
    environment:
      - OLLAMA_HOST=http://ollama:11434
    entrypoint: ["/bin/sh","-lc"]
    command: >
      set -euo pipefail;
      echo 'Pulling model: ${OLLAMA_MODEL_NAME:-llama3.1:8b-instruct-q4_K_M}';
      ollama pull ${OLLAMA_MODEL_NAME:-llama3.1:8b-instruct-q4_K_M};
      echo 'Model pulled successfully';
    restart: "no"

  api:
    container_name: rag-llm-api
    build: ./api
    restart: unless-stopped
    environment:
      WEAVIATE_URL: ${WEAVIATE_URL:-http://weaviate:8080}
      NOTES_SESSIONS_DIR: /notes/sessions
      NOTES_CHARACTERS_DIR: /notes/characters
      NOTES_LOCATIONS_DIR: /notes/locations
      NOTES_ORGANIZATIONS_DIR: /notes/organizations
      EMBED_MODEL_NAME: ${EMBED_MODEL_NAME:-BAAI/bge-small-en-v1.5}
      RERANKER_MODEL_NAME: ${RERANKER_MODEL_NAME:-BAAI/bge-reranker-base}
      ENABLE_RERANKER: ${ENABLE_RERANKER:-false}
      MAX_CONTEXT_CHUNKS: ${MAX_CONTEXT_CHUNKS:-8}
      # Generator Configuration - Set to "ollama" or "gemini"
      GENERATOR_PROVIDER: ${GENERATOR_PROVIDER:-ollama}
      # Ollama settings (used when GENERATOR_PROVIDER=ollama)
      OLLAMA_BASE_URL: http://ollama:11434
      OLLAMA_MODEL_NAME: ${OLLAMA_MODEL_NAME:-llama3.1:8b-instruct-q4_K_M}
      # Gemini settings (used when GENERATOR_PROVIDER=gemini)
      GEMINI_API_KEY: ${GEMINI_API_KEY:-}
      GEMINI_MODEL_NAME: ${GEMINI_MODEL_NAME:-gemini-1.5-flash}
    volumes:
      - ${NOTES_SESSIONS_DIR}:/notes/sessions:ro
      - ${NOTES_CHARACTERS_DIR}:/notes/characters:ro
      - ${NOTES_LOCATIONS_DIR}:/notes/locations:ro
      - ${NOTES_ORGANIZATIONS_DIR}:/notes/organizations:ro
      - api_cache:/root/.cache # speeds up model loads
    depends_on:
      - weaviate
    ports: ["8000:8000"]


volumes:
  weaviate_data:
  api_cache:
  ollama_data:
